{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "- train word embeddings by using `matichon.json`\n",
    "- use gensim `Word2Vec` model\n",
    "- find similar words, calculate cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, emoji, urllib, html\n",
    "from gensim.models import Word2Vec\n",
    "from pythainlp.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- custom tokenization function\n",
    "- remove all quatations and shrink newlines `\\n` and white spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenize(text):\n",
    "    ### REMOVE URL ###\n",
    "    text = html.unescape(urllib.parse.unquote(text)) # unescape for unicode, unquote for escaped URL\n",
    "    text = re.sub(r'https?.+?(?:\\s|$)', '', text) # remove URL link\n",
    "    ### REMOVE EMOJI ###\n",
    "    text = emoji.replace_emoji(text) # remove emoji\n",
    "    ### REPLACE ###\n",
    "    text = re.sub(r'[“”„\\\"]', '', text) # remove double quotations\n",
    "    text = re.sub(r'[‘’′′′′`\\']', '', text) # remove single quotations\n",
    "    text = re.sub(r'[\\n\\t\\u00a0\\xa0\\u3000\\u2002-\\u200a\\u202f]+', ' ', text) # shrink whitespaces e.g. good  boy -> good boy\n",
    "    text = re.sub(r'[\\r\\u200b\\ufeff]+', '', text) # remove non-breaking space\n",
    "    text = re.sub(r'เเ', 'แ', text)\n",
    "    ### SHRINK SOME REDUPLICATION ###\n",
    "    text = re.sub(r'าา+', 'า', text)\n",
    "    text = re.sub(r'ยย+', 'ย', text)\n",
    "    text = re.sub(r'ๆๆ+', 'ๆ', text)\n",
    "    text = re.sub(r'ะะ+', 'ะ', text)\n",
    "    ### am ###\n",
    "    text = re.sub(r'ํา','ำ', text) # o + า -> ำ\n",
    "    text = re.sub(r'\\u0E33([\\u0E48\\u0E49\\u0E4A\\u0E4B])', r'\\1'+'\\u0E33', text) # am + tone -> tone + am\n",
    "    ### TOKENIZE AND FILTERING ###\n",
    "    tokens = word_tokenize(text, keep_whitespace=False)\n",
    "    tokens = [token.strip('(').strip(')') for token in tokens] # remove parenthesis sticked to token\n",
    "    tokens = [token for token in tokens if re.match(r'[0-9A-zก-ไ][0-9A-zก-๙\\.\\-]*', token)] # remove non-word\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "- need only article, drop the other columns\n",
    "- tokenize article and store as list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>article</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>url</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ซาอุฯจ่อเปิดไฟเขียวให้สิทธิหญิงม่าย-หย่าร้างปก...</td>\n",
       "      <td>(2 ธ.ค.58) หนังสือพิมพ์อัล ริยาดของทางการซาอุด...</td>\n",
       "      <td>2015-12-04 03:35:18</td>\n",
       "      <td>foreign</td>\n",
       "      <td>https://www.matichon.co.th/foreign/news_293</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"ไก่อู\"ชี้ ตู่-เต้น ไม่ได้มีหน้าที่ตรวจสอบทุจร...</td>\n",
       "      <td>\"บิ๊กป้อม\" แจง ครม. มีความพยายามยุยงปลุกปั่นให...</td>\n",
       "      <td>2015-12-04 04:10:49</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.matichon.co.th/politics/news_329</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>เปิดใจ \"โบว์ แวนดา\" ระหว่างรอยิ้มได้เต็มที่ในว...</td>\n",
       "      <td>แม้จะทำหน้าที่ภรรยาที่ดีมาเฝ้าปอ – ทฤษฎี สหวงษ...</td>\n",
       "      <td>2015-12-04 06:30:11</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>https://www.matichon.co.th/entertainment/news_375</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"นาย ณภัทร\" ปลื้มคนชมแชมป์ขึ้นปกนิตยสารแห่งปี ...</td>\n",
       "      <td>กลายเป็นดาราหนุ่มเนื้อหอมแฟนคลับแน่น กระแสมาแร...</td>\n",
       "      <td>2015-12-04 07:10:26</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>https://www.matichon.co.th/entertainment/news_393</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>คอแทบหัก! แม่ยกแห่คล้องพวงมาลัยักษ์ \"บอย ศิริช...</td>\n",
       "      <td>แสดงดีจนเป็นที่ถูกอกถูกใจแฟนคลับ จนได้รับพวงมา...</td>\n",
       "      <td>2015-12-05 05:26:20</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>https://www.matichon.co.th/entertainment/news_445</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17104</th>\n",
       "      <td>โบว์ ณัฏฐา  แจ้งความ พล.ต.อ.ศรีวราห์ ถูกพาดพิง...</td>\n",
       "      <td>เมื่อวันที่ 5 ก.ค. ที่ สน.พญาไท น.ส.ณัฏฐา มหัท...</td>\n",
       "      <td>2018-07-05 13:25:45</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.matichon.co.th/politics/news_1029607</td>\n",
       "      <td>1029607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17105</th>\n",
       "      <td>ภาพบรรยากาศ ขุดทางระบายน้ำ เร่งนำ 13 ชีวิตออกจ...</td>\n",
       "      <td>วันที่ 5 กรกฎาคม เจ้าหน้าที่ขุดทางระบายน้ำที่ด...</td>\n",
       "      <td>2018-07-05 13:33:10</td>\n",
       "      <td>region</td>\n",
       "      <td>https://www.matichon.co.th/region/news_1029619</td>\n",
       "      <td>1029619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17106</th>\n",
       "      <td>สนช.ผ่านพ.ร.บ.สงฆ์ 3 วาระรวด พระมหากษัตริย์ทรง...</td>\n",
       "      <td>สนช.ผ่าน พ.ร.บ.สงฆ์ 3 วาระรวด \"วิษณุ\" แจงสาระส...</td>\n",
       "      <td>2018-07-05 13:33:27</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.matichon.co.th/politics/news_1029636</td>\n",
       "      <td>1029636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17107</th>\n",
       "      <td>นานาทรรศนะเพิ่มค่าปรับหมอ 5ล้านบ. สกัดเบี้ยว...</td>\n",
       "      <td>หมายเหตุ – จากกรณีที่ กระทรวงศึกษาธิการ (ศธ.) ...</td>\n",
       "      <td>2018-07-05 13:53:26</td>\n",
       "      <td>education</td>\n",
       "      <td>https://www.matichon.co.th/education/news_1029668</td>\n",
       "      <td>1029668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17108</th>\n",
       "      <td>วอน!! นายก ส.ปส.กช.ชง 'บิ๊กจิน' ช่วย น.ร.เอกชน...</td>\n",
       "      <td>เมื่อวันที่ 5 กรกรฎาคม นายศุภเสฏฐ์ คณากูล นายก...</td>\n",
       "      <td>2018-07-06 04:46:18</td>\n",
       "      <td>education</td>\n",
       "      <td>https://www.matichon.co.th/education/news_1029858</td>\n",
       "      <td>1029858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17109 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  \\\n",
       "0      ซาอุฯจ่อเปิดไฟเขียวให้สิทธิหญิงม่าย-หย่าร้างปก...   \n",
       "1      \"ไก่อู\"ชี้ ตู่-เต้น ไม่ได้มีหน้าที่ตรวจสอบทุจร...   \n",
       "2      เปิดใจ \"โบว์ แวนดา\" ระหว่างรอยิ้มได้เต็มที่ในว...   \n",
       "3      \"นาย ณภัทร\" ปลื้มคนชมแชมป์ขึ้นปกนิตยสารแห่งปี ...   \n",
       "4      คอแทบหัก! แม่ยกแห่คล้องพวงมาลัยักษ์ \"บอย ศิริช...   \n",
       "...                                                  ...   \n",
       "17104  โบว์ ณัฏฐา  แจ้งความ พล.ต.อ.ศรีวราห์ ถูกพาดพิง...   \n",
       "17105  ภาพบรรยากาศ ขุดทางระบายน้ำ เร่งนำ 13 ชีวิตออกจ...   \n",
       "17106  สนช.ผ่านพ.ร.บ.สงฆ์ 3 วาระรวด พระมหากษัตริย์ทรง...   \n",
       "17107  นานาทรรศนะเพิ่มค่าปรับหมอ 5ล้านบ. สกัดเบี้ยว...   \n",
       "17108  วอน!! นายก ส.ปส.กช.ชง 'บิ๊กจิน' ช่วย น.ร.เอกชน...   \n",
       "\n",
       "                                                 article                date  \\\n",
       "0      (2 ธ.ค.58) หนังสือพิมพ์อัล ริยาดของทางการซาอุด... 2015-12-04 03:35:18   \n",
       "1      \"บิ๊กป้อม\" แจง ครม. มีความพยายามยุยงปลุกปั่นให... 2015-12-04 04:10:49   \n",
       "2      แม้จะทำหน้าที่ภรรยาที่ดีมาเฝ้าปอ – ทฤษฎี สหวงษ... 2015-12-04 06:30:11   \n",
       "3      กลายเป็นดาราหนุ่มเนื้อหอมแฟนคลับแน่น กระแสมาแร... 2015-12-04 07:10:26   \n",
       "4      แสดงดีจนเป็นที่ถูกอกถูกใจแฟนคลับ จนได้รับพวงมา... 2015-12-05 05:26:20   \n",
       "...                                                  ...                 ...   \n",
       "17104  เมื่อวันที่ 5 ก.ค. ที่ สน.พญาไท น.ส.ณัฏฐา มหัท... 2018-07-05 13:25:45   \n",
       "17105  วันที่ 5 กรกฎาคม เจ้าหน้าที่ขุดทางระบายน้ำที่ด... 2018-07-05 13:33:10   \n",
       "17106  สนช.ผ่าน พ.ร.บ.สงฆ์ 3 วาระรวด \"วิษณุ\" แจงสาระส... 2018-07-05 13:33:27   \n",
       "17107  หมายเหตุ – จากกรณีที่ กระทรวงศึกษาธิการ (ศธ.) ... 2018-07-05 13:53:26   \n",
       "17108  เมื่อวันที่ 5 กรกรฎาคม นายศุภเสฏฐ์ คณากูล นายก... 2018-07-06 04:46:18   \n",
       "\n",
       "            category                                                url  \\\n",
       "0            foreign        https://www.matichon.co.th/foreign/news_293   \n",
       "1           politics       https://www.matichon.co.th/politics/news_329   \n",
       "2      entertainment  https://www.matichon.co.th/entertainment/news_375   \n",
       "3      entertainment  https://www.matichon.co.th/entertainment/news_393   \n",
       "4      entertainment  https://www.matichon.co.th/entertainment/news_445   \n",
       "...              ...                                                ...   \n",
       "17104       politics   https://www.matichon.co.th/politics/news_1029607   \n",
       "17105         region     https://www.matichon.co.th/region/news_1029619   \n",
       "17106       politics   https://www.matichon.co.th/politics/news_1029636   \n",
       "17107      education  https://www.matichon.co.th/education/news_1029668   \n",
       "17108      education  https://www.matichon.co.th/education/news_1029858   \n",
       "\n",
       "            id  \n",
       "0          293  \n",
       "1          329  \n",
       "2          375  \n",
       "3          393  \n",
       "4          445  \n",
       "...        ...  \n",
       "17104  1029607  \n",
       "17105  1029619  \n",
       "17106  1029636  \n",
       "17107  1029668  \n",
       "17108  1029858  \n",
       "\n",
       "[17109 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('data/matichon.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>category</th>\n",
       "      <th>article_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2 ธ.ค.58) หนังสือพิมพ์อัล ริยาดของทางการซาอุด...</td>\n",
       "      <td>foreign</td>\n",
       "      <td>[2, ธ.ค., 58, หนังสือพิมพ์, อัล, ริยาด, ของ, ท...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"บิ๊กป้อม\" แจง ครม. มีความพยายามยุยงปลุกปั่นให...</td>\n",
       "      <td>politics</td>\n",
       "      <td>[บิ๊ก, ป้อม, แจง, ครม., มี, ความพยายาม, ยุยง, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>แม้จะทำหน้าที่ภรรยาที่ดีมาเฝ้าปอ – ทฤษฎี สหวงษ...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>[แม้, จะ, ทำหน้าที่, ภรรยา, ที่, ดี, มา, เฝ้า,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>กลายเป็นดาราหนุ่มเนื้อหอมแฟนคลับแน่น กระแสมาแร...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>[กลายเป็น, ดารา, หนุ่ม, เนื้อ, หอม, แฟนคลับ, แ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>แสดงดีจนเป็นที่ถูกอกถูกใจแฟนคลับ จนได้รับพวงมา...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>[แสดง, ดี, จน, เป็นที่, ถูกอกถูกใจ, แฟนคลับ, จ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17104</th>\n",
       "      <td>เมื่อวันที่ 5 ก.ค. ที่ สน.พญาไท น.ส.ณัฏฐา มหัท...</td>\n",
       "      <td>politics</td>\n",
       "      <td>[เมื่อ, วันที่, 5, ก.ค., ที่, สน., พญาไท, น.ส....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17105</th>\n",
       "      <td>วันที่ 5 กรกฎาคม เจ้าหน้าที่ขุดทางระบายน้ำที่ด...</td>\n",
       "      <td>region</td>\n",
       "      <td>[วันที่, 5, กรกฎาคม, เจ้าหน้าที่, ขุด, ทาง, ระ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17106</th>\n",
       "      <td>สนช.ผ่าน พ.ร.บ.สงฆ์ 3 วาระรวด \"วิษณุ\" แจงสาระส...</td>\n",
       "      <td>politics</td>\n",
       "      <td>[สนช, ผ่าน, พ.ร.บ., สงฆ์, 3, วาระ, รวด, วิษณุ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17107</th>\n",
       "      <td>หมายเหตุ – จากกรณีที่ กระทรวงศึกษาธิการ (ศธ.) ...</td>\n",
       "      <td>education</td>\n",
       "      <td>[หมายเหตุ, จาก, กรณี, ที่, กระทรวงศึกษาธิการ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17108</th>\n",
       "      <td>เมื่อวันที่ 5 กรกรฎาคม นายศุภเสฏฐ์ คณากูล นายก...</td>\n",
       "      <td>education</td>\n",
       "      <td>[เมื่อ, วันที่, 5, กร, กร, ฎาคม, นาย, ศุภ, เสฏ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article       category  \\\n",
       "0      (2 ธ.ค.58) หนังสือพิมพ์อัล ริยาดของทางการซาอุด...        foreign   \n",
       "1      \"บิ๊กป้อม\" แจง ครม. มีความพยายามยุยงปลุกปั่นให...       politics   \n",
       "2      แม้จะทำหน้าที่ภรรยาที่ดีมาเฝ้าปอ – ทฤษฎี สหวงษ...  entertainment   \n",
       "3      กลายเป็นดาราหนุ่มเนื้อหอมแฟนคลับแน่น กระแสมาแร...  entertainment   \n",
       "4      แสดงดีจนเป็นที่ถูกอกถูกใจแฟนคลับ จนได้รับพวงมา...  entertainment   \n",
       "...                                                  ...            ...   \n",
       "17104  เมื่อวันที่ 5 ก.ค. ที่ สน.พญาไท น.ส.ณัฏฐา มหัท...       politics   \n",
       "17105  วันที่ 5 กรกฎาคม เจ้าหน้าที่ขุดทางระบายน้ำที่ด...         region   \n",
       "17106  สนช.ผ่าน พ.ร.บ.สงฆ์ 3 วาระรวด \"วิษณุ\" แจงสาระส...       politics   \n",
       "17107  หมายเหตุ – จากกรณีที่ กระทรวงศึกษาธิการ (ศธ.) ...      education   \n",
       "17108  เมื่อวันที่ 5 กรกรฎาคม นายศุภเสฏฐ์ คณากูล นายก...      education   \n",
       "\n",
       "                                          article_tokens  \n",
       "0      [2, ธ.ค., 58, หนังสือพิมพ์, อัล, ริยาด, ของ, ท...  \n",
       "1      [บิ๊ก, ป้อม, แจง, ครม., มี, ความพยายาม, ยุยง, ...  \n",
       "2      [แม้, จะ, ทำหน้าที่, ภรรยา, ที่, ดี, มา, เฝ้า,...  \n",
       "3      [กลายเป็น, ดารา, หนุ่ม, เนื้อ, หอม, แฟนคลับ, แ...  \n",
       "4      [แสดง, ดี, จน, เป็นที่, ถูกอกถูกใจ, แฟนคลับ, จ...  \n",
       "...                                                  ...  \n",
       "17104  [เมื่อ, วันที่, 5, ก.ค., ที่, สน., พญาไท, น.ส....  \n",
       "17105  [วันที่, 5, กรกฎาคม, เจ้าหน้าที่, ขุด, ทาง, ระ...  \n",
       "17106  [สนช, ผ่าน, พ.ร.บ., สงฆ์, 3, วาระ, รวด, วิษณุ,...  \n",
       "17107  [หมายเหตุ, จาก, กรณี, ที่, กระทรวงศึกษาธิการ, ...  \n",
       "17108  [เมื่อ, วันที่, 5, กร, กร, ฎาคม, นาย, ศุภ, เสฏ...  \n",
       "\n",
       "[17109 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## drop column except for article\n",
    "df.drop(columns=['date','headline','url','id'], inplace=True)\n",
    "\n",
    "## tokenize\n",
    "df['article_tokens'] = df['article'].apply(my_tokenize)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model with `gensim`\n",
    "\n",
    "how to use :\n",
    "[https://radimrehurek.com/gensim/models/word2vec.html](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "\n",
    "- input of `Word2Vec` must be **list of list of tokens**\n",
    "- `vector_size` : Dimensionality of the word vectors (usually 100-300)\n",
    "- `window` : Maximum distance between the current and predicted word within a sentence\n",
    "- `min_count` : Ignores all words with total frequency lower than this\n",
    "- `sg` : Training algorithm: 1 for skip-gram; otherwise CBOW. (skip-gram is recommended)\n",
    "- `epoch` : Number of iterations (epochs) over the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit\n",
    "## epoch=30, it may take over 5 minutes\n",
    "model = Word2Vec(sentences=df['article_tokens'], vector_size=100, window=5, min_count=3, sg=1, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "- `model.wv.most_similar(word, topn=xx)` gives the top N words with high cosine similarity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('รสชาติ', 0.8033337593078613),\n",
       " ('กลมกล่อม', 0.759904146194458),\n",
       " ('ลิ้มลอง', 0.7575984001159668),\n",
       " ('เมนู', 0.7486538290977478),\n",
       " ('ถูกปาก', 0.7146302461624146),\n",
       " ('ต้มยำ', 0.6957536935806274),\n",
       " ('จุใจ', 0.6873340606689453),\n",
       " ('ซี้ด', 0.6825014352798462),\n",
       " ('คุณหนู', 0.6794096827507019),\n",
       " ('โฮมเมด', 0.6754654049873352)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('อร่อย', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model.wv.similarity(word1, word2)` calculates the cosine similarity of the 2 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.798946"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## antonym is also similar word\n",
    "model.wv.similarity('ผู้ชาย', 'ผู้หญิง')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model.wv` behaves like a dictionary\n",
    "- e.g. `model.wv[word]` gives the vector of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.90128028e-01, -5.73293492e-02,  3.69323045e-02, -1.27124333e+00,\n",
       "       -8.65098089e-02, -4.09606583e-02,  3.47794771e-01,  5.94089210e-01,\n",
       "        1.56222284e-01, -4.75051105e-01,  1.36699881e-02, -8.80421340e-01,\n",
       "       -3.51476282e-01,  9.74132195e-02,  6.15406811e-01, -7.93572545e-01,\n",
       "       -6.17238641e-01, -4.84165341e-01, -4.52541485e-02, -2.17632592e-01,\n",
       "        6.32575870e-01, -4.34085846e-01,  3.74199748e-01, -1.23329811e-01,\n",
       "        2.12773457e-02, -2.75268018e-01,  3.35272551e-01,  4.45930421e-01,\n",
       "       -1.25464925e-03, -5.72437286e-01,  1.41862631e-01,  3.74919713e-01,\n",
       "        5.33240318e-01,  2.09685549e-01, -1.88794404e-01, -1.43954754e-01,\n",
       "       -1.03247866e-01, -3.99757683e-01,  6.40755892e-01,  1.23744950e-01,\n",
       "        1.82721719e-01,  4.75530922e-01,  3.28260869e-01, -4.49067146e-01,\n",
       "        6.69365823e-01,  3.04452572e-02, -3.66540253e-01,  1.57527760e-01,\n",
       "       -6.30566776e-02,  6.21690869e-01,  3.41537625e-01, -4.48221117e-01,\n",
       "       -9.88482177e-01, -2.27254465e-01,  4.01044041e-01,  5.35834551e-01,\n",
       "       -1.62793025e-01,  1.79797113e-01,  6.01472706e-02,  8.31872106e-01,\n",
       "        1.08915120e-01,  2.66145408e-01,  6.51843622e-02,  1.96116894e-01,\n",
       "        2.31004566e-01,  2.04596832e-01, -2.18357127e-02,  6.57813370e-01,\n",
       "       -3.88207346e-01,  3.77361983e-01, -4.86038387e-01, -7.65105069e-01,\n",
       "        5.70360959e-01, -1.13331050e-01,  9.83891726e-01,  6.50847077e-01,\n",
       "        5.18204391e-01,  5.57260439e-02, -1.90648194e-02,  5.18850386e-01,\n",
       "        2.15703979e-01, -4.69677329e-01, -9.58791226e-02,  4.14513499e-01,\n",
       "        3.79179358e-01,  5.87408304e-01,  1.73574716e-01,  7.37780809e-01,\n",
       "        3.12210113e-01,  2.73553908e-01,  1.29755259e-01,  5.75079262e-01,\n",
       "       -2.44281045e-03,  2.96031833e-01,  1.02966398e-01,  7.24865854e-01,\n",
       "        5.23625672e-01,  1.42811820e-01, -7.70922899e-01,  4.65765782e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['อร่อย']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model.wv.most_similar()` can add/subtract vectors\n",
    "- use argument `positive` and `negative`, e.g. `model.wv.most_similar(positive=[w1, w2], negative=[w3])`\n",
    "\n",
    "\n",
    "~~~python\n",
    "'ปักกิ่ง' - 'จีน' + 'ญี่ปุ่น' : model.wv.most_similar(positive=['ปักกิ่ง', 'ญี่ปุ่น'], negative=['จีน'])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('โตเกียว', 0.6826370358467102),\n",
       " ('กรุง', 0.630218505859375),\n",
       " ('เยรูซาเลม', 0.5580424666404724),\n",
       " ('มะนิลา', 0.5503596067428589),\n",
       " ('ฮาเนดะ', 0.5496883392333984),\n",
       " ('อาบูดาบี', 0.5293322205543518),\n",
       " ('เยอรมนี', 0.5223350524902344),\n",
       " ('โอซากา', 0.5204705595970154),\n",
       " ('จาการ์ตา', 0.5170543193817139),\n",
       " ('เบอร์ลิน', 0.5170120000839233)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ปักกิ่ง - จีน + ญี่ปุ่น\n",
    "model.wv.most_similar(positive=['ปักกิ่ง', 'ญี่ปุ่น'], negative=['จีน'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save & load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the model\n",
    "## the same model is in `data` folder\n",
    "model.save(\"data/word2vec_matichon.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('เซ็กซี่', 0.6849587559700012),\n",
       " ('สวยงาม', 0.6509441137313843),\n",
       " ('ซิกซ์แพ็ก', 0.6408807039260864),\n",
       " ('สะบึม', 0.6297575235366821),\n",
       " ('น่ารัก', 0.628147542476654),\n",
       " ('เปล่งประกาย', 0.6210014820098877),\n",
       " ('สะพรั่ง', 0.6196946501731873),\n",
       " ('อึ๋ม', 0.6060378551483154),\n",
       " ('เชือดเฉือน', 0.5976887345314026),\n",
       " ('บิกินี่', 0.595427930355072)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load pre-trained model \n",
    "model_loaded = Word2Vec.load(\"data/word2vec_matichon.model\")\n",
    "model_loaded.wv.most_similar('สวย')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "- go to https://projector.tensorflow.org/\n",
    "- prepare 2 files:\n",
    "    1. `tsv` file of all vectors (without index, without header)\n",
    "    2. `tsv` file of labels (without index, with header)\n",
    "- click \"Load\" and upload files\n",
    "- it shows neighbor words in 3D plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>freq/10M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.147107</td>\n",
       "      <td>0.205480</td>\n",
       "      <td>-0.080089</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>-0.110583</td>\n",
       "      <td>-0.359767</td>\n",
       "      <td>0.186321</td>\n",
       "      <td>0.264107</td>\n",
       "      <td>-0.145018</td>\n",
       "      <td>0.053605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146914</td>\n",
       "      <td>0.328782</td>\n",
       "      <td>0.044164</td>\n",
       "      <td>-0.107805</td>\n",
       "      <td>-0.103107</td>\n",
       "      <td>0.094986</td>\n",
       "      <td>-0.065493</td>\n",
       "      <td>ที่</td>\n",
       "      <td>124850</td>\n",
       "      <td>202167.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.076751</td>\n",
       "      <td>0.106975</td>\n",
       "      <td>-0.088567</td>\n",
       "      <td>-0.155876</td>\n",
       "      <td>0.131924</td>\n",
       "      <td>-0.413932</td>\n",
       "      <td>0.050694</td>\n",
       "      <td>0.405921</td>\n",
       "      <td>-0.200009</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287021</td>\n",
       "      <td>0.205203</td>\n",
       "      <td>0.251952</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>-0.087677</td>\n",
       "      <td>-0.002882</td>\n",
       "      <td>0.151624</td>\n",
       "      <td>และ</td>\n",
       "      <td>118744</td>\n",
       "      <td>192280.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.248766</td>\n",
       "      <td>0.236299</td>\n",
       "      <td>-0.139819</td>\n",
       "      <td>-0.158100</td>\n",
       "      <td>0.108476</td>\n",
       "      <td>-0.211760</td>\n",
       "      <td>0.100985</td>\n",
       "      <td>0.349802</td>\n",
       "      <td>-0.093654</td>\n",
       "      <td>0.041861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.271012</td>\n",
       "      <td>0.309146</td>\n",
       "      <td>0.211601</td>\n",
       "      <td>-0.102019</td>\n",
       "      <td>-0.161443</td>\n",
       "      <td>-0.143182</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>ใน</td>\n",
       "      <td>98174</td>\n",
       "      <td>158971.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017607</td>\n",
       "      <td>0.330226</td>\n",
       "      <td>-0.128629</td>\n",
       "      <td>0.018312</td>\n",
       "      <td>0.143110</td>\n",
       "      <td>-0.360320</td>\n",
       "      <td>-0.297999</td>\n",
       "      <td>0.193926</td>\n",
       "      <td>-0.059721</td>\n",
       "      <td>-0.189001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288652</td>\n",
       "      <td>0.388178</td>\n",
       "      <td>-0.151375</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>0.012237</td>\n",
       "      <td>-0.119617</td>\n",
       "      <td>-0.043767</td>\n",
       "      <td>มี</td>\n",
       "      <td>84284</td>\n",
       "      <td>136479.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.126914</td>\n",
       "      <td>0.096425</td>\n",
       "      <td>-0.209569</td>\n",
       "      <td>0.019580</td>\n",
       "      <td>-0.174211</td>\n",
       "      <td>-0.008858</td>\n",
       "      <td>0.744829</td>\n",
       "      <td>-0.203719</td>\n",
       "      <td>-0.405993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447429</td>\n",
       "      <td>0.289066</td>\n",
       "      <td>0.165223</td>\n",
       "      <td>0.089111</td>\n",
       "      <td>0.048112</td>\n",
       "      <td>-0.004735</td>\n",
       "      <td>-0.147302</td>\n",
       "      <td>การ</td>\n",
       "      <td>74873</td>\n",
       "      <td>121240.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.147107  0.205480 -0.080089  0.009322 -0.110583 -0.359767  0.186321   \n",
       "1 -0.076751  0.106975 -0.088567 -0.155876  0.131924 -0.413932  0.050694   \n",
       "2  0.248766  0.236299 -0.139819 -0.158100  0.108476 -0.211760  0.100985   \n",
       "3  0.017607  0.330226 -0.128629  0.018312  0.143110 -0.360320 -0.297999   \n",
       "4  0.009582  0.126914  0.096425 -0.209569  0.019580 -0.174211 -0.008858   \n",
       "\n",
       "          8         9        10  ...        94        95        96        97  \\\n",
       "0  0.264107 -0.145018  0.053605  ...  0.146914  0.328782  0.044164 -0.107805   \n",
       "1  0.405921 -0.200009  0.023447  ... -0.287021  0.205203  0.251952  0.006049   \n",
       "2  0.349802 -0.093654  0.041861  ... -0.271012  0.309146  0.211601 -0.102019   \n",
       "3  0.193926 -0.059721 -0.189001  ... -0.288652  0.388178 -0.151375  0.011995   \n",
       "4  0.744829 -0.203719 -0.405993  ... -0.447429  0.289066  0.165223  0.089111   \n",
       "\n",
       "         98        99       100  word   count  freq/10M  \n",
       "0 -0.103107  0.094986 -0.065493   ที่  124850  202167.5  \n",
       "1 -0.087677 -0.002882  0.151624   และ  118744  192280.1  \n",
       "2 -0.161443 -0.143182 -0.138014    ใน   98174  158971.5  \n",
       "3  0.012237 -0.119617 -0.043767    มี   84284  136479.6  \n",
       "4  0.048112 -0.004735 -0.147302   การ   74873  121240.6  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make dataframe \n",
    "wv_df = pd.DataFrame(model.wv.vectors, columns=np.arange(1, 101)) # value of vectors\n",
    "wv_df['word'] = model.wv.index_to_key # all vocabs\n",
    "wv_df['count'] = wv_df['word'].apply(lambda x: model.wv.get_vecattr(x, 'count')) # get word count of each word\n",
    "wv_df['freq/10M'] = (wv_df['count'] * 10000000 / wv_df['count'].sum()).round(1) # calculate word frequency in 10M words\n",
    "\n",
    "wv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save to tsv file\n",
    "## vector tsv files (without index, header)\n",
    "wv_df.drop(columns=['word','count','freq/10M'], axis=1).to_csv('data/wv.tsv', sep='\\t', index=False, header=False)\n",
    "\n",
    "## label tsv files (with label `word` and `word frequency`)\n",
    "wv_df[['word','freq/10M']].to_csv('data/wv_label.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![wv_visualization](image/wv_visualization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
