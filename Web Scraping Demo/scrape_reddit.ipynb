{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import json, os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instantiate webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## instantiate driver\n",
    "## check the version of Google Chrome and download correct version of chromedriver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get page of \"social grep\", which gived old posts of subreddit\n",
    "## original reddit url = 'https://www.reddit.com/r/xxxxxxxxx/'\n",
    "\n",
    "subreddit = 'languagetechnology' # choose by yourself\n",
    "start_date = '2010-01-01' # choose by yourself\n",
    "url = f'https://socialgrep.com/search?query=%2Fr%2F{subreddit}%2Cafter%3A{start_date}&order_by=oldest'\n",
    "\n",
    "driver.get(url)\n",
    "repeat_time, waiting_time = 4, 2\n",
    "\n",
    "## scroll to the bottom of the page and wait\n",
    "for i in range(repeat_time):\n",
    "    driver.execute_script(f\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    sleep(waiting_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example of one post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to scrape\n",
    "def get_content(post, subreddit):\n",
    "    try:\n",
    "        vote = int(post.select_one('span.text-info').text)\n",
    "    except:\n",
    "        vote = 0\n",
    "    try:\n",
    "        title = post.a.text\n",
    "    except:\n",
    "        return None\n",
    "    try:\n",
    "        text = post.select_one('div.post_content').get_text(separator='\\n').strip()\n",
    "        if text == '':\n",
    "            text = None\n",
    "    except:\n",
    "        text = None\n",
    "    date = post.select_one('h6.card-subtitle').text.split(',')[1].strip()\n",
    "\n",
    "    if text == None and title == f\"/r/{subreddit.lower()}\":\n",
    "        return None\n",
    "    else:\n",
    "        return {\n",
    "            \"vote\" : vote,\n",
    "            \"title\" : title,\n",
    "            \"text\" : text,\n",
    "            \"date\" : date\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vote': 1, 'title': 'Tokenization', 'text': None, 'date': '2010-03-10'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(driver.page_source)\n",
    "posts = soup.select('div.card-body') # content is under here\n",
    "\n",
    "get_content(posts[1], subreddit) # show one example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for loop with datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'{subreddit}.json'):\n",
    "    ## resume scraping from the last date in the json file\n",
    "    with open(f'{subreddit}.json', 'r') as f:\n",
    "        scraped_data = json.load(f)\n",
    "    new_date = scraped_data[-1]['date']\n",
    "    url = f'https://socialgrep.com/search?query=%2Fr%2F{subreddit}%2Cafter%3A{new_date}&order_by=oldest'\n",
    "else:\n",
    "    ## if the file not exists, create a new list\n",
    "    scraped_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:31<00:00, 15.14s/it]\n"
     ]
    }
   ],
   "source": [
    "## scrape and append to `scraped_data`\n",
    "## RUN THIS CELL AGAIN AND AGAIN until getting the latest post\n",
    "\n",
    "for _ in tqdm(range(10)): # set repeat time \n",
    "\n",
    "    ## scroll to the bottom of the page and wait\n",
    "    driver.get(url)\n",
    "    for i in range(4):\n",
    "        driver.execute_script(f\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        sleep(2)\n",
    "\n",
    "    ## get HTML\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    posts = soup.select('div.card-body')\n",
    "\n",
    "    ## iterate each post\n",
    "    for post in posts:\n",
    "        one_post_dict = get_content(post, subreddit)\n",
    "        if one_post_dict != None:\n",
    "            scraped_data.append(one_post_dict)\n",
    "\n",
    "    ## save to json\n",
    "    with open(f'{subreddit}.json', 'w') as f:\n",
    "        json.dump(scraped_data, f, indent=False, ensure_ascii=False)\n",
    "\n",
    "    ## set new date\n",
    "    new_date = scraped_data[-1]['date']\n",
    "    url = f'https://socialgrep.com/search?query=%2Fr%2F{subreddit}%2Cafter%3A{new_date}&order_by=oldest'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to dataframe and drop duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vote</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Example based machine translation</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tokenization</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Maximum Entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Parts-Of-Speech Tagging</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Interlingual Machine Translation</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6971</th>\n",
       "      <td>5</td>\n",
       "      <td>Sentiment analysis using the Sine Waves</td>\n",
       "      <td>I have created a sentiment analysis, which all...</td>\n",
       "      <td>2023-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6972</th>\n",
       "      <td>2</td>\n",
       "      <td>Integrate NLP into a web-application</td>\n",
       "      <td>My company has a SaaS-based web app. We intend...</td>\n",
       "      <td>2023-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6973</th>\n",
       "      <td>6</td>\n",
       "      <td>Title: AI voice bot app: Impersonating Andrew ...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2023-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6974</th>\n",
       "      <td>2</td>\n",
       "      <td>Mitigate the context size limit in LLMs with s...</td>\n",
       "      <td>The following idea seems like an obvious thing...</td>\n",
       "      <td>2023-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6975</th>\n",
       "      <td>5</td>\n",
       "      <td>Computational linguistics masters</td>\n",
       "      <td>Hi! \\n\\n\\nI'm currently studying in my first y...</td>\n",
       "      <td>2023-04-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5758 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      vote                                              title  \\\n",
       "0        1                  Example based machine translation   \n",
       "1        1                                       Tokenization   \n",
       "2        1                                    Maximum Entropy   \n",
       "3        1                            Parts-Of-Speech Tagging   \n",
       "4        1                   Interlingual Machine Translation   \n",
       "...    ...                                                ...   \n",
       "6971     5            Sentiment analysis using the Sine Waves   \n",
       "6972     2               Integrate NLP into a web-application   \n",
       "6973     6  Title: AI voice bot app: Impersonating Andrew ...   \n",
       "6974     2  Mitigate the context size limit in LLMs with s...   \n",
       "6975     5                  Computational linguistics masters   \n",
       "\n",
       "                                                   text       date  \n",
       "0                                                  None 2010-03-10  \n",
       "1                                                  None 2010-03-10  \n",
       "2                                                  None 2010-03-13  \n",
       "3                                                  None 2010-03-13  \n",
       "4                                                  None 2010-10-07  \n",
       "...                                                 ...        ...  \n",
       "6971  I have created a sentiment analysis, which all... 2023-04-04  \n",
       "6972  My company has a SaaS-based web app. We intend... 2023-04-04  \n",
       "6973                                          [removed] 2023-04-04  \n",
       "6974  The following idea seems like an obvious thing... 2023-04-04  \n",
       "6975  Hi! \\n\\n\\nI'm currently studying in my first y... 2023-04-05  \n",
       "\n",
       "[5758 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(f'{subreddit}.json').drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vote       0\n",
       "title      0\n",
       "text     735\n",
       "date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## missing value in text\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vote</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Looking for good paraphrase corpus (not Micros...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2011-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>Looking for a comparison of probabilistic lang...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2012-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>If you own or know Jurafsky and Martin's book ...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2012-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>SemGraph - library for reading and visualising...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2012-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>Clustering Jeopardy! questions together with P...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2012-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6948</th>\n",
       "      <td>1</td>\n",
       "      <td>Starting a career in Speech AI</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2023-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6958</th>\n",
       "      <td>0</td>\n",
       "      <td>Learning prompt engineering for someone non-te...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2023-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6966</th>\n",
       "      <td>13</td>\n",
       "      <td>How does \"next word prediction\" sample the nex...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2023-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6970</th>\n",
       "      <td>1</td>\n",
       "      <td>LANGUAGE LEARNERS: How is it going!</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2023-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6973</th>\n",
       "      <td>6</td>\n",
       "      <td>Title: AI voice bot app: Impersonating Andrew ...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2023-04-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>831 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      vote                                              title       text  \\\n",
       "9        1  Looking for good paraphrase corpus (not Micros...  [removed]   \n",
       "14       1  Looking for a comparison of probabilistic lang...  [removed]   \n",
       "16       1  If you own or know Jurafsky and Martin's book ...  [removed]   \n",
       "19       1  SemGraph - library for reading and visualising...  [removed]   \n",
       "26       2  Clustering Jeopardy! questions together with P...  [deleted]   \n",
       "...    ...                                                ...        ...   \n",
       "6948     1                     Starting a career in Speech AI  [deleted]   \n",
       "6958     0  Learning prompt engineering for someone non-te...  [deleted]   \n",
       "6966    13  How does \"next word prediction\" sample the nex...  [deleted]   \n",
       "6970     1                LANGUAGE LEARNERS: How is it going!  [deleted]   \n",
       "6973     6  Title: AI voice bot app: Impersonating Andrew ...  [removed]   \n",
       "\n",
       "           date  \n",
       "9    2011-12-06  \n",
       "14   2012-02-14  \n",
       "16   2012-04-21  \n",
       "19   2012-06-15  \n",
       "26   2012-11-12  \n",
       "...         ...  \n",
       "6948 2023-03-25  \n",
       "6958 2023-03-30  \n",
       "6966 2023-04-01  \n",
       "6970 2023-04-03  \n",
       "6973 2023-04-04  \n",
       "\n",
       "[831 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## text includes [removed] [deleted]\n",
    "df[df['text'].isin(['[removed]', '[deleted]'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
